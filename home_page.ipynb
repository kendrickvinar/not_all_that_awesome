{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS109A Final Project: Data Driven March Madness \n",
    "\n",
    "**Harvard University**<br>\n",
    "**Fall 2016**<br>\n",
    "**Authors: Kurt Bullard and Kendrick Vinar**<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home Page\n",
    "___________________\n",
    "\n",
    "- [Introduction](#Introduction)\n",
    "- [Abstract](#Abstract)\n",
    "- [A Deeper Dive](#a_deeper_dive)\n",
    "- [Acknowledgements](#Acknowledgements)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "------------------\n",
    "\n",
    "March Madness is the colloquial phrase for the pinnacle event of college basketball, the NCAA Men's Basketball Tournament.  Each year in mid-March, sixty-four teams compete for the college basketball national championship. Unlike the NBA playoffs, in which teams play a best-of-seven series to advance, the national champion of college basketball is crowned via a single-elimination bracket. Hence, the madness -- a single loss can erase the significance of an excellent regular season for a favorite (see Kentucky in 2015), and a deep tournament run for an underdog can earn one a place in March Madness lore for years (see Davidson in 2008). What makes March Madness special is its unpredictability. Every year there are dramatic upsets and tournament runs. Despite millions of brackets submitted each year, there has never been a perfect bracket. \n",
    "\n",
    "Each year basketball experts, pundits, and casual fans alike fill out a bracket to predict who will win the 63 games each year. Theories and opinions on crafting the ideal bracket abound. Who do you listen to? We decided to put aside our theories and let the data speak. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract \n",
    "_______________\n",
    "\n",
    "We created models to generate March Madness predictions using different machine learning algorithms, including logistic regression, SVM, and random forests. We analyzed data from 2003 through the 2016 season. We used a 7-year window time-series method to create seven years of predictions from 2010 to 2016. Each of those years of predictions are trained on seven years of prior tournament data. Three of those years, 2010-2012, we used to tune our models. We used the last four years from 2013-2016 to test the efficacy of our model. We evaluated the performance of our models with a common scoring system used by ESPN, Yahoo Sports, and CBS Sports. Our model generates probabilities for the likelihood of each team advancing in a given matchup, samples from a binomial distribution over the likelihood of the favorite winning, and advances the team that is most likely to advance according to the draw from the distribution. \n",
    "\n",
    "[say something about results here]\n",
    "\n",
    "\n",
    "Put this elsewhere: \n",
    "\n",
    "Under this system, one receives $2^{n-1}$ points for a correct prediction in the $n-th$ round. For example, one receives one point for a correct prediction in the 1st round, four points for a correct prediction in the 3rd round, and thirty-two points for correctly predicting the winner. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'a_deeper_dive'></a>\n",
    "\n",
    "## A Deeper Dive\n",
    "_________________\n",
    "\n",
    "Below are three links to learn more about our project:\n",
    "\n",
    "- [8.1.1 Regression Trees](#8.1.1-Regression-Trees)\n",
    "- [8.1.2 Classification Trees](#8.1.2-Classification-Trees)\n",
    "- [Lab: 8.3.1 Fitting Classification Trees](#8.3.1-Fitting-Classification-Trees)\n",
    "- [Harvard Home Page](http://www.harvard.edu)\n",
    "\n",
    "The first page explains in much greater detail the individual steps of our project, justifications for our rationale, problems we encountered, and decisions we had to make. This portion is intended to be an accessible explanation of our process and reasoning.\n",
    "\n",
    "The second page contains the first half of our code. This portion deals with the messy details of importing the data, merging data from different sources, creating variables, eliminating variables, and more. We include text explanations of our process throughout, however much of the details are intended for those with some exposure to data and machine learning. \n",
    "\n",
    "Last, the third page contains the second half of our code. This portion deals primarily with tuning models, training models, and reporting results. Again, there are explanations of our process throughout, however greater technical proficiency is expected. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgements\n",
    "_____________________\n",
    "\n",
    "We would like to thank Michael Farrell, our project TF, for his advice, feedback, and availability throughout this process. His direction has been invaluable. \n",
    "\n",
    "We would also like to thank Kevin Rader, Pavlos Protopapas, and Weiwei Pan, the instructors of CS109a, for the time they have invested in our growth and learning throughout the semester. We are very grateful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
